{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCBMnieEP4yH"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain faiss-cpu pypdf2  python-dotenv"
      ],
      "metadata": {
        "id": "-FE5-TlWQP4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "AYxgTlqgR5c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains.retrieval import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain import hub"
      ],
      "metadata": {
        "id": "jDxoXYlcRp45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "pdf_path = \"\"\n",
        "reader = PdfReader(pdf_path)\n",
        "documents = [page.extract_text() for page in reader.pages if page.extract_text()]\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=30, separator=\"\\n\")\n",
        "split_texts = text_splitter.split_text(\"\\n\".join(documents))\n",
        "split_documents = [Document(page_content=text) for text in split_texts]"
      ],
      "metadata": {
        "id": "Bp66TKjuXo96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_huggingface"
      ],
      "metadata": {
        "id": "oggH69-AaQ-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "tRGTtS8oZHR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "\n",
        "vectorstore = FAISS.from_documents(split_documents, embeddings)\n",
        "vectorstore.save_local(\"faiss_index\")\n",
        "new_vectorstore = FAISS.load_local(\n",
        "    \"faiss_index\", embeddings, allow_dangerous_deserialization=True\n",
        ")"
      ],
      "metadata": {
        "id": "4X50o9SobhjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq"
      ],
      "metadata": {
        "id": "1zg3RIYnfKzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain import hub\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains.retrieval import create_retrieval_chain\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"\n",
        "\n",
        "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "retriever = new_vectorstore.as_retriever()\n",
        "llm = ChatGroq(model_name=\"mixtral-8x7b-32768\")\n",
        "\n",
        "\n",
        "combine_docs_chain = create_stuff_documents_chain(\n",
        "    prompt=retrieval_qa_chat_prompt,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "retrieval_chain = create_retrieval_chain(\n",
        "    retriever, combine_docs_chain\n",
        ")"
      ],
      "metadata": {
        "id": "rzO94k5FdjeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = retrieval_chain.invoke({\"input\": \"What was the subject of the visit\"})\n",
        "print(res[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wdJbxgyfwBL",
        "outputId": "f34dcc5e-d3a4-4853-f969-6366b0f2d066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The subject of the visit was a routine nail trim (POD-Nail trim) for the patient, Antonio Figueroa.\n"
          ]
        }
      ]
    }
  ]
}